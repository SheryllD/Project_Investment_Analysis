{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analysis: Start-ups, Investement & Funding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Cleaning the Dataset \n",
    "1. We began by reviewing and cleaning the dataset to understand its structure and key patterns.\n",
    "2. We imported the necessary libraries for data cleaning.\n",
    "3. We loaded the CSV dataset and used df.shape to examine the number of rows and columns.\n",
    "4. We checked for duplicate rows using df.duplicated().sum().\n",
    "5. We generated summary statistics with df.describe() and df.describe(include=\"all\") to gain insights into numerical and categorical data.\n",
    "\n",
    "## Handling Missing Data \n",
    "6. Before deciding how to handle missing values, we needed to check how many missing values exist in each column using. We then identify missing values with (df.isnull().sum()).\n",
    "7. Once we know which columns contain missing values, we choose a methhod to handle them based on the data type and context.\n",
    "8. We reviewed if there are any missing rows and make a decision to either drop them if needed with df.dropna(inplace=True).\n",
    "9. If missing values are significant, we could replace them instead of dropping the data. For numerical data we would use: df.fillna(df.mean()), For categorical data: df.fillna(\"Unknown\")\n",
    "These steps ensure a well-structured and refined dataset for accurate analysis.\n",
    "\n",
    "## Handle Duplicates\n",
    "10. For handling duplicates reviewed and identify duplicate rows with df.duplicated().sum(). \\n\n",
    "If this was the case we would drop these duplicates (df.drop_duplicates(inplace=True))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display \n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Clean Pikl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
